# -*- coding: utf-8 -*-
"""BERT_RecommendationSystem

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qhETLe-JkcPKIFwsFmBLIRS1WVTm5lum
"""

import pandas as pd
from sentence_transformers import SentenceTransformer

# Load the data into a pandas DataFrame
df = pd.read_excel('Online Retail.xlsx')
#test comment
df.head()

df.shape

# remove rows with missing values
df = df.dropna(subset=['InvoiceNo', 'Description', 'Quantity', 'UnitPrice'])

# remove rows with negative quantity or price
df = df[(df.Quantity > 0) & (df.UnitPrice > 0)]

# exclude cancelled invoices that start with 'C'
df = df[~df['InvoiceNo'].apply(lambda x: str(x).startswith(('C', 'A')))]

df.shape

df.head()

# change Description column to string data type
df['Description'] = df['Description'].astype(str)

# Convert the Description column to lowercase
df['Description'] = df['Description'].str.lower()

# Remove any punctuations and special characters from the Description column
# df['Description'] = df['Description'].str.replace('[^\w\s]','')

df.head()

# from nltk.tokenize import word_tokenize

# Tokenize the Description column by splitting each sentence into words
# df['Description'] = df['Description'].apply(word_tokenize)

# df.head()

# from nltk.stem import PorterStemmer

# # Stem or lemmatize the words in the Description column to reduce the number of unique words and group together similar words
# ps = PorterStemmer()
# df['Description'] = df['Description'].apply(lambda x: [ps.stem(word) for word in x])

# df.head()

# df.shape

df['Description'].isna().any()

df = df.reset_index(drop=True)

# df

device = 'cuda'
model = SentenceTransformer('bert-base-nli-mean-tokens', device=device)

# Create embeddings of the Description unique column
embeddings = model.encode(df['Description'].unique(), show_progress_bar=True)

# Add embeddings as a new column
# df['Description Embeddings'] = list(embeddings)

embeddings.shape

from sklearn.cluster import KMeans

from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity

# Define the number of clusters
num_clusters = 50

# Compute cosine similarity between embeddings
#cos_sim = cosine_similarity(embeddings)

# Create KMeans object with the desired number of clusters
kmeans = KMeans(n_clusters=num_clusters)

# Fit the KMeans model to the cosine similarity matrix
kmeans.fit(embeddings)

clusters = kmeans.predict(embeddings)

len(clusters)

df['Description'].unique()[clusters==221]

# Create embeddings of the Description column
embeddings_df = model.encode(df['Description'], show_progress_bar=True)

clusters_df = kmeans.predict(embeddings_df)

clusters_df

len(clusters_df)

df['Clusters'] = clusters_df

df

invoices = df['InvoiceNo'].unique()



import numpy as np
import scipy.stats as stats

# for invoice in invoices:
data = {}
data['InvoiceNo'] = []
data['Recommended_Item'] = []
for invoice in invoices:
  tdf = df[df['InvoiceNo'] == invoice]
  cluster = stats.mode(tdf['Clusters'])[0][0]
  desc = list(set(df[df["Clusters"] == cluster]["Description"].unique().tolist()) - set(tdf['Description'].unique().tolist()))
  data['InvoiceNo'].append(invoice)
  data['Recommended_Item'].append(np.random.choice(desc))
  # print("Invoice no:", invoice)
  # print(tdf['Description'])
  # print("Recommendation:", desc[0])
  # print("\n\n")

final_df = pd.DataFrame(data)

final_df

final_df['Recommended_Item'].mode()

# Generate the summary table
summary_table = pd.DataFrame(columns=['Description', 'Invoice Count', 'Recommendation Count'])

unique_recs = data["Recommendation"].unique()

# iterate over the unique recommended items and add them to the summary table
for item in tqdm(unique_recs):
    invoice_count = data[data['Description'] == item]['InvoiceNo'].nunique()
    recommendation_count = data[data['Recommendation'] == item]['InvoiceNo'].count()
    summary_table = pd.concat([summary_table, pd.DataFrame([[item, invoice_count, recommendation_count]], columns=summary_table.columns)], ignore_index=True)